{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Uses GPU if available\n",
    "model_name = 'facebook/mbart-large-50-many-to-many-mmt'\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "def get_backtranslation(text, src='en_XX', tgt='ru_RU'):\n",
    "    pivot_lang_txt = get_translation(text, src, tgt)\n",
    "    back_to_src_txt = get_translation(pivot_lang_txt, tgt, src)\n",
    "    return back_to_src_txt\n",
    "\n",
    "def get_translation(text, src, tgt):\n",
    "    tokenizer.src_lang = src\n",
    "    encoded = tokenizer(text, return_tensors='pt', max_length=60, truncation=True, padding=True).to(device)\n",
    "    output = model.generate(**encoded, forced_bos_token_id= tokenizer.lang_code_to_id[tgt])\n",
    "    decoded = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylev\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import language_tool_python\n",
    "\n",
    "# initializing LanguageTool and SentenceTransformer model\n",
    "sen_model = SentenceTransformer('paraphrase-MiniLM-L3-v2').to(device)\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "def get_distance(src_txt, paraphrased_txt):\n",
    "    \"\"\"Returns levenschtein distance at word level between src_text and paraphrase\"\"\"\n",
    "    return pylev.levenschtein(src_txt.split(), paraphrased_txt.split())\n",
    "\n",
    "def get_similarity(src_txt, paraphrased_txt):\n",
    "    \"\"\"Returns cosine similarity between source and paraphrase sentence vectors\"\"\"\n",
    "    src_txt_encoded = sen_model.encode(src_txt, convert_to_tensor=True)\n",
    "    paraphrased_txt_encoded = sen_model.encode(paraphrased_txt, convert_to_tensor=True)\n",
    "    return util.pytorch_cos_sim(src_txt_encoded , paraphrased_txt_encoded).item()\n",
    "\n",
    "def get_num_grammatical_errors(paraphrased_txt):\n",
    "    \"\"\"Returns the number of errors calculated by LanguageTool\"\"\"\n",
    "    return len(tool.check(paraphrased_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_label(source, paraphrase):\n",
    "    \"\"\"Returns label that indicates how large the changes were between source and paraphrase text\"\"\"\n",
    "    distance = get_distance(source, paraphrase)\n",
    "    dist_percentage = distance/len(source.split())\n",
    "    if dist_percentage <=0.25:\n",
    "        return 'small'\n",
    "    elif dist_percentage <=0.5:\n",
    "        return 'medium'\n",
    "    elif dist_percentage<=0.75:\n",
    "        return 'large'\n",
    "    else:\n",
    "        return 'gigantic'\n",
    "\n",
    "        \n",
    "def get_length_label(source, paraphrase):\n",
    "    \"\"\"Returns the label that indicates whether to reduce, match, or expand source text\"\"\"\n",
    "    para_length = len(paraphrase.split())\n",
    "    source_length = len(source.split())\n",
    "    if para_length == source_length:\n",
    "        return 'match'\n",
    "    elif source_length > para_length :\n",
    "        return 'reduce'\n",
    "    else:\n",
    "        return 'expand'\n",
    "\n",
    "def get_prefix_text(source, paraphrase):\n",
    "    \"\"\"Gets distance and length label. Then returns string with desired format\"\"\"\n",
    "    length_label = get_length_label(source, paraphrase)\n",
    "    distance_label = get_distance_label(source, paraphrase)\n",
    "    return f\"Paraphrase: {distance_label} changes, {length_label} input. {source}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def generate_paraphrases():\n",
    "    with open('open_stax_sentences.json', 'r', encoding='utf-8') as r:\n",
    "        open_stax_sentences = json.load(r)\n",
    "    batch = []  # batching to speed up the translation model\n",
    "    batch_size = 32\n",
    "    for sentence in tqdm(open_stax_sentences):\n",
    "        batch.append(sentence)\n",
    "        if len(batch) == batch_size:\n",
    "            # gets a batch of back-translated text that are potential paraphrases\n",
    "            paraphrases = get_backtranslation(batch)\n",
    "            for src, paraphrase in zip(batch, paraphrases):\n",
    "                modified_src = get_prefix_text(src, paraphrase)\n",
    "                if get_distance(src, paraphrase) >= 3 and get_similarity(src, paraphrase) > 0.8 and not get_num_grammatical_errors(paraphrase):\n",
    "                    yield {\"Source\": modified_src, 'Target': paraphrase}\n",
    "            batch = []\n",
    "\n",
    "\n",
    "paraphrase_data = list(generate_paraphrases())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "def clean_spaces(sentence):\n",
    "    \"\"\"Just gets rid of the spaces before/after punctuation\"\"\"\n",
    "    return re.sub(' ([.,;:-?!])', r'\\1', sentence)\n",
    "\n",
    "\n",
    "paws_data = load_dataset('paws', 'labeled_final')['train']\n",
    "for item in paws_data:\n",
    "    if item['label'] == 1:\n",
    "        paraphrase_data.extend({\"Source\": get_prefix_text(clean_spaces(item['sentence1'])), \"Target\": clean_spaces(item['sentence2'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(paraphrase_data)\n",
    "train_ds = paraphrase_data[:-1000]\n",
    "test_ds = paraphrase_data[-1000:]\n",
    "\n",
    "with open('train_ds.json', 'w', encoding='utf-8') as w:\n",
    "    json.dump(train_ds, w, ensure_ascii=False, indent=2)\n",
    "    \n",
    "with open('test_ds.json', 'w', encoding='utf-8') as w:\n",
    "    json.dump(test_ds, w, ensure_ascii=False, indent=2)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b35f54f48fbac3e5ffa46ab7cc15b584275b74e35baab85b001e32619a37ec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
